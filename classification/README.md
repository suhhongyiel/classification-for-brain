# TAU Synthetic Data Classification System

A comprehensive deep learning framework for classifying AD (Alzheimer's Disease) vs CN (Cognitively Normal) using TAU-PET synthetic brain imaging data. This system implements 3D Vision Transformer (ViT) and 3D ResNet18 models with enhancement mechanisms specifically designed for small-scale 3D brain images (64x64x64).

## üìÅ Project Structure

```
classification/
‚îú‚îÄ‚îÄ data/                           # Data directory
‚îÇ   ‚îî‚îÄ‚îÄ syn_data_mapping.csv       # Generated mapping file
‚îú‚îÄ‚îÄ result/                         # Experiment results
‚îÇ   ‚îú‚îÄ‚îÄ cross_validation_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ experiment_summary.csv
‚îÇ   ‚îî‚îÄ‚îÄ *_detailed.csv             # Per-fold detailed results
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ models.py                   # 3D ViT and ResNet18 implementations
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ data_mapper.py             # Data mapping utilities
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py                 # PyTorch dataset and data loading
‚îÇ   ‚îú‚îÄ‚îÄ trainer.py                 # Training and evaluation loops
‚îÇ   ‚îî‚îÄ‚îÄ cross_validation.py       # Cross-validation management
‚îú‚îÄ‚îÄ configs/                       # Configuration files (optional)
‚îú‚îÄ‚îÄ main.py                        # Main execution script
‚îî‚îÄ‚îÄ README.md                      # This file
```

## üöÄ Features

### Models
- **3D Vision Transformer (ViT)**: Custom 3D ViT with patch-based attention for brain imaging
- **3D ResNet18**: MONAI-based 3D ResNet with customizable architecture
- **Enhancement Mechanisms**: Optional feature enhancement for small image resolution (64x64x64)

### Training Features
- **10-Fold Cross Validation**: Stratified splits ensuring balanced AD/CN distribution
- **Real-time Metrics**: Live monitoring of AUC, F1-score, and Balanced Accuracy
- **Class Imbalance Handling**: Focal loss and class weighting for imbalanced datasets
- **Early Stopping**: Prevents overfitting with patience-based stopping
- **Multiple Optimizers**: AdamW, Adam, SGD with learning rate scheduling

### Enhancement for Small Images
- Multi-scale feature extraction
- Feature attention mechanisms
- Residual connections with attention weighting
- Data augmentation specifically designed for 3D brain images

### Experiment Management
- **Parameter Tuning**: Grid search on single fold for rapid hyperparameter optimization
- **Result Logging**: Comprehensive CSV and JSON result storage
- **Resume Capability**: Continue interrupted experiments
- **Detailed Analytics**: Per-subject prediction analysis

## üõ†Ô∏è Installation

### Requirements
```bash
# Core dependencies
torch>=1.12.0
torchvision>=0.13.0
monai>=1.0.0
nibabel>=3.2.0
scikit-learn>=1.1.0
pandas>=1.3.0
numpy>=1.21.0
tqdm>=4.64.0
```

### Environment Setup
```bash
# Create conda environment
conda create -n tau-classification python=3.8
conda activate tau-classification

# Install PyTorch (adjust for your CUDA version)
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia

# Install MONAI and other dependencies
pip install monai[all]
pip install nibabel scikit-learn pandas tqdm

# Or install from requirements
pip install -r requirements.txt
```

## üìä Data Setup

### 1. Data Structure
The system expects synthetic TAU-PET data generated by your DDPM model, stored in the following structure:
```
/nas/research/save_10fold_experience/pods/hysuh2/home/03-inference-file/TAU-DDPM-proposed/TAU3-1/
‚îú‚îÄ‚îÄ fold_1_test_nii_results/
‚îÇ   ‚îú‚îÄ‚îÄ fold_1_subj_sub-ADNI002S4213_sess_ses-M072_pred.nii.gz
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ fold_2_test_nii_results/
‚îî‚îÄ‚îÄ ...
```

### 2. Create Data Mapping
First, create the data mapping CSV that links synthetic data to diagnosis labels:

```bash
cd classification
python main.py --mode data-mapping
```

This will:
- Parse all 10 folds of synthetic data
- Extract subject IDs from filenames
- Map to diagnosis labels from `/home/data/TAU-data.csv`
- Create `/home/classification/data/syn_data_mapping.csv`

## üèÉ‚Äç‚ôÇÔ∏è Usage

### Quick Start Examples

#### 1. Single Fold Test (Recommended for first run)
```bash
# Test ResNet18 on fold 1 with quick training
python main.py --mode single --fold 1 --model resnet18 --quick-tune --epochs 5

# Test with enhancement mechanisms
python main.py --mode single --fold 1 --model resnet18 --enhance-features --quick-tune
```

#### 2. Parameter Tuning
```bash
# Tune hyperparameters on fold 1
python main.py --mode tune --fold 1 --model resnet18

# Results saved to: result/tuning/resnet18_parameter_tuning.csv
```

#### 3. Full Cross-Validation
```bash
# Run all models and configurations on all folds
python main.py --mode full

# Run specific models with custom settings
python main.py --mode full --models resnet18 --enhance-options False True --epochs 30

# Run on specific folds only
python main.py --mode full --folds 1 2 3 --epochs 20 --batch-size 16
```

### Advanced Usage

#### Custom Configuration
```bash
# Use specific hyperparameters
python main.py --mode full \
    --models resnet18 vit \
    --enhance-options True \
    --epochs 50 \
    --batch-size 8 \
    --learning-rate 1e-4 \
    --optimizer adamw \
    --loss-function focal

# Use configuration file
python main.py --mode full --config-file configs/best_config.json
```

#### Resume Interrupted Experiments
```bash
# Analyze existing results
python main.py --mode resume --results-dir ./result

# Continue from where you left off (just rerun the same command)
python main.py --mode full  # Will skip completed experiments
```

## üìà Results and Analysis

### Output Files

1. **cross_validation_results.csv**: Summary of all experiments
   - Columns: fold, model_name, enhance_small_features, test_auc, test_f1, test_bacc, etc.

2. **experiment_summary.csv**: Aggregated statistics per model configuration
   - Mean, std, min, max for each metric across folds

3. **Detailed results**: `{model}_{enhanced}_{fold}_detailed.csv`
   - Per-subject predictions and probabilities

4. **Model checkpoints**: `{model}_fold_{fold}_best.pth`
   - Best performing model weights for each fold

### Key Metrics
- **AUC**: Area Under the ROC Curve (primary metric)
- **F1**: Weighted F1-score
- **BACC**: Balanced Accuracy (important for imbalanced data)
- **Accuracy**: Standard accuracy

### Expected Performance
Based on the characteristics of synthetic 64x64x64 brain images:
- **Baseline models**: AUC ~0.65-0.75
- **Enhanced models**: AUC ~0.70-0.80
- **Best configurations**: AUC >0.80 possible with optimal hyperparameters

## ‚öôÔ∏è Configuration Options

### Model Parameters
```python
# 3D ViT Configuration
{
    "img_size": [64, 64, 64],
    "patch_size": [8, 8, 8],
    "embed_dim": 768,
    "depth": 12,
    "num_heads": 12,
    "dropout_rate": 0.1
}

# 3D ResNet18 Configuration
{
    "spatial_dims": 3,
    "n_input_channels": 1,
    "layers": [2, 2, 2, 2],
    "dropout_prob": 0.2
}
```

### Training Parameters
```python
{
    "batch_size": 8,
    "num_epochs": 50,
    "learning_rate": 1e-4,
    "weight_decay": 1e-5,
    "optimizer": "adamw",
    "scheduler": "cosine",
    "loss_function": "focal",
    "early_stopping_patience": 15
}
```

## üî¨ Research Features

### Enhancement Mechanisms for Small Images
Given the challenging 64x64x64 resolution, several enhancement techniques are implemented:

1. **Multi-scale Feature Extraction**: Convolutional layers with different kernel sizes
2. **Feature Attention**: Attention-weighted feature fusion
3. **Residual Enhancement**: Residual connections with learned attention weights
4. **Advanced Data Augmentation**: 3D-specific augmentations for brain images

### Class Imbalance Handling
With ~81 AD vs ~329 CN samples, the system includes:
- **Focal Loss**: Focuses on hard examples and rare classes
- **Class Weighting**: Inverse frequency weighting
- **Stratified Sampling**: Maintains class balance across train/val/test splits

### Robust Evaluation
- **Stratified 10-Fold CV**: Each fold maintains class distribution
- **Multiple Metrics**: Not just accuracy, but AUC, F1, and BACC
- **Statistical Analysis**: Mean, std, confidence intervals across folds

## üêõ Troubleshooting

### Common Issues

1. **CUDA Out of Memory**
   ```bash
   # Reduce batch size
   python main.py --batch-size 4
   
   # Use fewer workers
   python main.py --num-workers 2
   ```

2. **Data Loading Errors**
   ```bash
   # Check if data mapping exists
   ls classification/data/syn_data_mapping.csv
   
   # Recreate mapping if needed
   python main.py --mode data-mapping
   ```

3. **Import Errors**
   ```bash
   # Check if in correct directory
   cd classification
   
   # Install missing dependencies
   pip install monai nibabel
   ```

### Performance Tips

1. **For Quick Testing**: Use `--quick-tune` flag for reduced epochs
2. **For Memory Efficiency**: Reduce `--batch-size` and `--num-workers`
3. **For Speed**: Use single model: `--models resnet18`
4. **For Debugging**: Use single fold: `--mode single --fold 1`

## üìù Example Workflows

### 1. First-time Setup and Testing
```bash
# 1. Create data mapping
python main.py --mode data-mapping

# 2. Quick test on one fold
python main.py --mode single --fold 1 --model resnet18 --quick-tune

# 3. Parameter tuning
python main.py --mode tune --fold 1 --model resnet18

# 4. Run with best parameters on 3 folds
python main.py --mode full --folds 1 2 3 --epochs 30
```

### 2. Full Experimental Pipeline
```bash
# 1. Comprehensive parameter tuning
python main.py --mode tune --fold 1 --model resnet18
python main.py --mode tune --fold 1 --model vit

# 2. Full cross-validation with optimized parameters
python main.py --mode full --epochs 50 --learning-rate 5e-5

# 3. Analysis of results
python main.py --mode resume
```

### 3. Comparative Study
```bash
# Compare baseline vs enhanced models
python main.py --mode full --models resnet18 --enhance-options False True

# Compare different models
python main.py --mode full --models resnet18 vit --enhance-options True

# Statistical significance testing
python -c "
import pandas as pd
results = pd.read_csv('result/cross_validation_results.csv')
print(results.groupby(['model_name', 'enhance_small_features'])['test_auc'].describe())
"
```

## üìö Citation

If you use this system in your research, please cite:

```bibtex
@software{tau_synthetic_classification,
  title={TAU Synthetic Data Classification System},
  author={Your Name},
  year={2024},
  url={https://github.com/suhhongyiel/gene-emb}
}
```

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## üìû Support

For questions or issues:
1. Check the troubleshooting section above
2. Look at existing issues in the repository
3. Create a new issue with detailed description and error logs

## üîÑ Version History

- **v1.0.0**: Initial release with 3D ViT and ResNet18 models
- **v1.1.0**: Added enhancement mechanisms for small images
- **v1.2.0**: Implemented parameter tuning and advanced logging

---

**Happy Experimenting!** üß†üî¨ 